<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Training Bottlenecks: A Harsh Reality of AI Models | ThirdAI</title><meta name=keywords content="Blog,Deep Learning,BOLT,CPU,Training,Neural Network,AI"><meta name=description content="There is no silver bullet AI modality. Better predictions require a constant cycle of feature engineering, hyper-parameter tuning, training, and testing the resultant models. The most time-consuming stage of any AI-powered application pipeline is fine tuning, which often requires repeated iterations of network training to expose performance gains. Even with AutoML and Neural Architecture Search (NAS), engineering features and hammering out other task-specific pipelines in an AI system is unavoidable."><meta name=author content="ThirdAILabs"><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=//thirdailabs.github.io/static/css/stylesheet.min.2b65407eaa69bd34c5c68586f0d2ea90d4de57878dab3703c9d50c07b038c297.css integrity="sha256-K2VAfqppvTTFxoWG8NLqkNTeV4eNqzcDydUMB7A4wpc=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=//thirdailabs.github.io/static/js/highlight.min.b801c3817c6b951b39b4f5adde05c84b6d72be498309c6b09454d361bf3f3b02.js integrity="sha256-uAHDgXxrlRs5tPWt3gXIS21yvkmDCcawlFTTYb8/OwI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=//thirdailabs.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=//thirdailabs.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=//thirdailabs.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=//thirdailabs.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=//thirdailabs.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.99.1"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Training Bottlenecks: A Harsh Reality of AI Models"><meta property="og:description" content="There is no silver bullet AI modality. Better predictions require a constant cycle of feature engineering, hyper-parameter tuning, training, and testing the resultant models. The most time-consuming stage of any AI-powered application pipeline is fine tuning, which often requires repeated iterations of network training to expose performance gains. Even with AutoML and Neural Architecture Search (NAS), engineering features and hammering out other task-specific pipelines in an AI system is unavoidable."><meta property="og:type" content="article"><meta property="og:url" content="//thirdailabs.github.io/resources/blog/training-bottlenecks/"><meta property="og:image" content="//thirdailabs.github.io/%3Cimage%20path/url%3E"><meta property="article:section" content="resources"><meta property="article:published_time" content="2022-01-22T00:00:00+00:00"><meta property="article:modified_time" content="2022-01-22T00:00:00+00:00"><meta property="og:site_name" content="ThirdAI"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="//thirdailabs.github.io/%3Cimage%20path/url%3E"><meta name=twitter:title content="Training Bottlenecks: A Harsh Reality of AI Models"><meta name=twitter:description content="There is no silver bullet AI modality. Better predictions require a constant cycle of feature engineering, hyper-parameter tuning, training, and testing the resultant models. The most time-consuming stage of any AI-powered application pipeline is fine tuning, which often requires repeated iterations of network training to expose performance gains. Even with AutoML and Neural Architecture Search (NAS), engineering features and hammering out other task-specific pipelines in an AI system is unavoidable."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Resources","item":"//thirdailabs.github.io/resources/"},{"@type":"ListItem","position":2,"name":"Blog","item":"//thirdailabs.github.io/resources/blog/"},{"@type":"ListItem","position":3,"name":"Training Bottlenecks: A Harsh Reality of AI Models","item":"//thirdailabs.github.io/resources/blog/training-bottlenecks/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Training Bottlenecks: A Harsh Reality of AI Models","name":"Training Bottlenecks: A Harsh Reality of AI Models","description":"There is no silver bullet AI modality. Better predictions require a constant cycle of feature engineering, hyper-parameter tuning, training, and testing the resultant models. The most time-consuming stage of any AI-powered application pipeline is fine tuning, which often requires repeated iterations of network training to expose performance gains. Even with AutoML and Neural Architecture Search (NAS), engineering features and hammering out other task-specific pipelines in an AI system is unavoidable.","keywords":["Blog","Deep Learning","BOLT","CPU","Training","Neural Network","AI"],"articleBody":"There is no silver bullet AI modality. Better predictions require a constant cycle of feature engineering, hyper-parameter tuning, training, and testing the resultant models. The most time-consuming stage of any AI-powered application pipeline is fine tuning, which often requires repeated iterations of network training to expose performance gains. Even with AutoML and Neural Architecture Search (NAS), engineering features and hammering out other task-specific pipelines in an AI system is unavoidable.\nDomain adaptation and transfer learning are cheap but inferior alternatives to constant retraining Currently, domain adaptation and transfer learning alternatives are the best way to sidestep the expenses of training. But such solutions are appealing only where retraining is entirely prohibitive. Otherwise, if accuracy matters and resources allow, it’s always a good idea to rebuild the model from scratch. In nearly all cases, retraining from scratch results in a significant performance improvement. Instead of avoiding retraining, the path forward for AI research is to develop more efficient training.\nImprovements to model deployment have also been much discussed as the future of AI development. Here, the task is to search for models where inference is cheap. Perhaps the search space can be quantized, or pruned, or some other efficient design can be brought to bear. But in the end, it circles back to fast training. Cutting-edge research using Deep Reinforcement Learning for efficient ASICs is still bottlenecked by how fast we can train and search for the most energy-efficient configuration.\nThe faster we validate complex network architectures, the quicker we move the AI innovation wheel Improvements in architecture validation efficiency pay immediate and constant dividends for the process of creating AI solutions. The quicker we can validate different methods, the earlier we reach dominance for a specific task.\nThis is why we’re excited to reveal BOLT, our solution to the need for faster and more accessible neural network training. Via purely algorithmic innovations, BOLT can supercharge commodity CPUs for training large models. Not only can BOLT train commercial-sized neural networks on CPUs, it can do so with superior performance even when compared to GPUs using the strongest competing software. Best of all, our algorithmic improvements don’t rely on specialized hardware: BOLT can be used on virtually any CPU (Intel, AMD, ARM).\nYou can read more about BOLT here, or try it out now. BTW: If this research sounds like fun, we’re hiring.\n","wordCount":"391","inLanguage":"en","image":"//thirdailabs.github.io/%3Cimage%20path/url%3E","datePublished":"2022-01-22T00:00:00Z","dateModified":"2022-01-22T00:00:00Z","author":{"@type":"Person","name":"ThirdAILabs"},"mainEntityOfPage":{"@type":"WebPage","@id":"//thirdailabs.github.io/resources/blog/training-bottlenecks/"},"publisher":{"@type":"Organization","name":"ThirdAI","logo":{"@type":"ImageObject","url":"//thirdailabs.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=list id=top><script>window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><div class=hero><header class=header><nav class=nav><div class=logo><a href=//thirdailabs.github.io/ accesskey=h title="ThirdAI (Alt + H)"><img class=icon alt=logo aria-label=logo height=35></img>ThirdAI</a>
<span class=logo-switches></span></div><ul id=menu><li><div class=dropdown><button class=drop-button>Solutions</button><div class=drop-content><a href=//thirdailabs.github.io/solutions/question-answering>Question Answering</a>
<a href=//thirdailabs.github.io/solutions/text-classification>Sentiment Classification</a>
<a href=//thirdailabs.github.io/solutions/product-recommendation>Product Recommendation</a></div></div></li><li><a href=//thirdailabs.github.io/engine/bolt><div class=menu-item>Engine</div></a></li><li><div class=dropdown><button class=drop-button>Resources</button><div class=drop-content><a href=//thirdailabs.github.io/resources/documentation>Documentation</a>
<a href=//thirdailabs.github.io/resources/webinars>Webinars</a>
<a href=//thirdailabs.github.io/resources/blog>Blog</a>
<a href=//thirdailabs.github.io/resources/demo>Demo</a></div></div></li><li><div class=dropdown><button class=drop-button>Company</button><div class=drop-content><a href=//thirdailabs.github.io/company/about>About</a>
<a href=//thirdailabs.github.io/company/careers/>Careers</a></div></div></li><li><a href=//thirdailabs.github.io/contact/><div class=menu-item>Contact</div></a></li></ul><input class=checkbox type=checkbox><div class=hamburger-lines><span class="line line1"></span>
<span class="line line2"></span>
<span class="line line3"></span></div><div class=mobile-menu-items><li><a href=//thirdailabs.github.io/solutions/>Solutions</a></li><li><a href=//thirdailabs.github.io/engine/bolt>Engine</a></li><li><a href=//thirdailabs.github.io/resources/>Resources</a></li><li><a href=//thirdailabs.github.io/company/>Company</a></li><li><a href=//thirdailabs.github.io/contact/>Contact</a></li></div></nav></header></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=//thirdailabs.github.io/>Home</a>&nbsp;»&nbsp;<a href=//thirdailabs.github.io/resources/blog/>Blog</a>&nbsp;»&nbsp;<a>Training Bottlenecks: A Harsh Reality of AI Models</a></div><h1 class=post-title>Training Bottlenecks: A Harsh Reality of AI Models</h1><div class=post-meta><span title="2022-01-22 00:00:00 +0000 UTC">January 22, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;ThirdAILabs</div></header><div class=post-content><img class=bottleneck-graphic alt="Bottleneck Graphic"><p>There is no silver bullet AI modality. Better predictions require a constant cycle of feature engineering, hyper-parameter tuning, training, and testing the resultant models. The most time-consuming stage of any AI-powered application pipeline is fine tuning, which often requires repeated iterations of network training to expose performance gains. Even with AutoML and Neural Architecture Search (NAS), engineering features and hammering out other task-specific pipelines in an AI system is unavoidable.</p><h3 id=domain-adaptation-and-transfer-learning-are-cheap-but-inferior-alternatives-to-constant-retraining>Domain adaptation and transfer learning are cheap but inferior alternatives to constant retraining</h3><p>Currently, domain adaptation and transfer learning alternatives are the best way to sidestep the expenses of training. But such solutions are appealing only where retraining is entirely prohibitive. Otherwise, if accuracy matters and resources allow, it&rsquo;s always a good idea to rebuild the model from scratch. In nearly all cases, retraining from scratch results in a significant performance improvement. Instead of avoiding retraining, the path forward for AI research is to develop more efficient training.</p><p>Improvements to model deployment have also been much discussed as the future of AI development. Here, the task is to search for models where inference is cheap. Perhaps the search space can be quantized, or pruned, or some other efficient design can be brought to bear. But in the end, it circles back to fast training. Cutting-edge research using Deep Reinforcement Learning for efficient ASICs is still bottlenecked by how fast we can train and search for the most energy-efficient configuration.</p><h3 id=the-faster-we-validate-complex-network-architectures-the-quicker-we-move-the-ai-innovation-wheel>The faster we validate complex network architectures, the quicker we move the AI innovation wheel</h3><p>Improvements in architecture validation efficiency pay immediate and constant dividends for the process of creating AI solutions. The quicker we can validate different methods, the earlier we reach dominance for a specific task.</p><p>This is why we&rsquo;re excited to reveal <a href=//thirdailabs.github.io/engine/bolt>BOLT</a>, our solution to the need for faster and more accessible neural network training. Via purely algorithmic innovations, BOLT can supercharge commodity CPUs for training large models. Not only can BOLT train commercial-sized neural networks on CPUs, it can do so with superior performance even when compared to GPUs using the strongest competing software. Best of all, our algorithmic improvements don’t rely on specialized hardware: BOLT can be used on virtually any CPU (Intel, AMD, ARM).</p><p>You can read more about BOLT <a href=//thirdailabs.github.io/engine/bolt>here</a>, or <a href=//thirdailabs.github.io/resources/demo>try it out now</a>. BTW: If this research sounds like fun, <a href=//thirdailabs.github.io/company/careers>we&rsquo;re hiring</a>.</p></div><footer class=post-footer><ul class=post-tags><li><a href=//thirdailabs.github.io/tags/blog/>Blog</a></li><li><a href=//thirdailabs.github.io/tags/deep-learning/>Deep Learning</a></li><li><a href=//thirdailabs.github.io/tags/bolt/>BOLT</a></li><li><a href=//thirdailabs.github.io/tags/cpu/>CPU</a></li><li><a href=//thirdailabs.github.io/tags/training/>Training</a></li><li><a href=//thirdailabs.github.io/tags/neural-network/>Neural Network</a></li><li><a href=//thirdailabs.github.io/tags/ai/>AI</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Training Bottlenecks: A Harsh Reality of AI Models on twitter" href="https://twitter.com/intent/tweet/?text=Training%20Bottlenecks%3a%20A%20Harsh%20Reality%20of%20AI%20Models&url=%2f%2fthirdailabs.github.io%2fresources%2fblog%2ftraining-bottlenecks%2f&hashtags=Blog%2cDeepLearning%2cBOLT%2cCPU%2cTraining%2cNeuralNetwork%2cAI"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Training Bottlenecks: A Harsh Reality of AI Models on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=%2f%2fthirdailabs.github.io%2fresources%2fblog%2ftraining-bottlenecks%2f&title=Training%20Bottlenecks%3a%20A%20Harsh%20Reality%20of%20AI%20Models&summary=Training%20Bottlenecks%3a%20A%20Harsh%20Reality%20of%20AI%20Models&source=%2f%2fthirdailabs.github.io%2fresources%2fblog%2ftraining-bottlenecks%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Training Bottlenecks: A Harsh Reality of AI Models on facebook" href="https://facebook.com/sharer/sharer.php?u=%2f%2fthirdailabs.github.io%2fresources%2fblog%2ftraining-bottlenecks%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></div></footer></article></main><footer class=fat-footer><div class=wrapper><div class=fat-footer-social><a href=https://twitter.com/ThirdAILab><img src=//thirdailabs.github.io/images/twitter.svg width=50px class=footer-icon></a>
<a href=https://www.linkedin.com/company/thirdai-corp><img src=//thirdailabs.github.io/images/linkedin.svg width=45px class=footer-icon></a>
<a href=#><img src=//thirdailabs.github.io/images/facebook.svg width=22px class=footer-icon></a></div><div class=fat-footer-menus><div class=menu-container><div class=menu-title><h3>solutions</h3></div><div class=menu-content><ul><li><a href=//thirdailabs.github.io/solutions/question-answering>Question Answering</a></li><li><a href=//thirdailabs.github.io/solutions/text-classification>Text Classification</a></li><li><a href=//thirdailabs.github.io/solutions/product-recommendation>Product Recommendation</a></li></ul></div></div><div class=menu-container><div class=menu-title><h3>engine</h3></div><div class=menu-content><ul><li><a href=//thirdailabs.github.io/engine/bolt>BOLT</a></li></ul></div></div><div class=menu-container><div class=menu-title><h3>resources</h3></div><div class=menu-content><ul><li><a href=#>Documentation</a></li><li><a href=#>Webinars</a></li><li><a href=//thirdailabs.github.io/resources/blog>Blog</a></li><li><a href=//thirdailabs.github.io/resources/demo>Demo</a></li></ul></div></div><div class=menu-container><div class=menu-title><h3>company</h3></div><div class=menu-content><ul><li><a href=//thirdailabs.github.io/company/about>About us</a></li><li><a href=//thirdailabs.github.io/company/careers>Careers</a></li><li><a href=//thirdailabs.github.io/contact>Contact</a></li></ul></div></div></div></div><div class=copyright-wrapper><div class=logo><a href=//thirdailabs.github.io/><img src=//thirdailabs.github.io/images/logo-dark.png alt=logo height=35></img>ThirdAI</a></div><div class=copyright><span>&copy; 2022 <a href=//thirdailabs.github.io/>ThirdAI</a></span></div></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>